{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-39e4d515b9f6>\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 47, in <module>\n",
      "    import numpy as np\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\__init__.py\", line 145, in <module>\n",
      "    from . import core\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\__init__.py\", line 72, in <module>\n",
      "    from . import numeric\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\numeric.py\", line 34, in <module>\n",
      "    from ._asarray import asarray, asanyarray\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 6, in <module>\n",
      "    from .overrides import (\n",
      "ImportError: cannot import name 'set_array_function_like_doc' from 'numpy.core.overrides' (C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\overrides.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 47, in <module>\n",
      "    import numpy as np\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\__init__.py\", line 145, in <module>\n",
      "    from . import core\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\__init__.py\", line 72, in <module>\n",
      "    from . import numeric\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\numeric.py\", line 34, in <module>\n",
      "    from ._asarray import asarray, asanyarray\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 6, in <module>\n",
      "    from .overrides import (\n",
      "ImportError: cannot import name 'set_array_function_like_doc' from 'numpy.core.overrides' (C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\overrides.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-39e4d515b9f6>\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 47, in <module>\n",
      "    import numpy as np\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\__init__.py\", line 145, in <module>\n",
      "    from . import core\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\__init__.py\", line 72, in <module>\n",
      "    from . import numeric\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\numeric.py\", line 34, in <module>\n",
      "    from ._asarray import asarray, asanyarray\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 6, in <module>\n",
      "    from .overrides import (\n",
      "ImportError: cannot import name 'set_array_function_like_doc' from 'numpy.core.overrides' (C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\overrides.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2048, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1437, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1337, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1194, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 47, in <module>\n",
      "    import numpy as np\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\__init__.py\", line 145, in <module>\n",
      "    from . import core\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\__init__.py\", line 72, in <module>\n",
      "    from . import numeric\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\numeric.py\", line 34, in <module>\n",
      "    from ._asarray import asarray, asanyarray\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 6, in <module>\n",
      "    from .overrides import (\n",
      "ImportError: cannot import name 'set_array_function_like_doc' from 'numpy.core.overrides' (C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\overrides.py)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-39e4d515b9f6>\", line 1, in <module>\n",
      "    import tensorflow as tf\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 99, in <module>\n",
      "    from tensorflow_core import *\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 47, in <module>\n",
      "    import numpy as np\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\__init__.py\", line 145, in <module>\n",
      "    from . import core\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\__init__.py\", line 72, in <module>\n",
      "    from . import numeric\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\numeric.py\", line 34, in <module>\n",
      "    from ._asarray import asarray, asanyarray\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 6, in <module>\n",
      "    from .overrides import (\n",
      "ImportError: cannot import name 'set_array_function_like_doc' from 'numpy.core.overrides' (C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\overrides.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'ImportError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3435, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2048, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1437, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1337, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1194, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3147, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3357, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2048, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1437, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1337, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1212, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 34, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 47, in <module>\n",
      "    import numpy as np\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\__init__.py\", line 145, in <module>\n",
      "    from . import core\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\__init__.py\", line 72, in <module>\n",
      "    from . import numeric\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\numeric.py\", line 34, in <module>\n",
      "    from ._asarray import asarray, asanyarray\n",
      "  File \"C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\_asarray.py\", line 6, in <module>\n",
      "    from .overrides import (\n",
      "ImportError: cannot import name 'set_array_function_like_doc' from 'numpy.core.overrides' (C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\numpy\\core\\overrides.py)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단순 선형 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "# 가설 준비(Wx + b)\n",
    "hypot = W * x_train\n",
    "\n",
    "# 비용함수(평균제곱함수)\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))\n",
    "# ------------------- 텐서플로우의 그래프 완성 -------------------#\n",
    "\n",
    "# 비용함수를 그래프로 그려보기(3장 p7, inear Regression cost함수 최소화)\n",
    "sess = tf.Session()\n",
    "\n",
    "cost_val = []\n",
    "for i in range(-30, 50):\n",
    "    result = sess.run(cost, feed_dict={W:i*0.1})\n",
    "    cost_val.append(result)\n",
    "    \n",
    "plt.plot(cost_val)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사 하강(Gradient descent) 알고리즘을 이용한 가중치 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 경사하강법 = 현재 가중치에서 알파(러닝메이트)를 빼주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [-0.07892525] 15.737907\n",
      "1 [0.3780249] 4.4820976\n",
      "2 [0.62173164] 1.2804447\n",
      "3 [0.75170857] 0.36975265\n",
      "4 [0.8210296] 0.110711284\n",
      "5 [0.8580008] 0.03702845\n",
      "6 [0.8777188] 0.01606976\n",
      "7 [0.88823503] 0.010108202\n",
      "8 [0.8938437] 0.0084124645\n",
      "9 [0.89683497] 0.007930113\n",
      "10 [0.89843035] 0.0077929124\n",
      "11 [0.8992812] 0.007753892\n",
      "12 [0.899735] 0.0077427938\n",
      "13 [0.899977] 0.007739634\n",
      "14 [0.9001061] 0.007738733\n",
      "15 [0.9001749] 0.0077384748\n",
      "16 [0.90021163] 0.007738404\n",
      "17 [0.90023124] 0.007738384\n",
      "18 [0.9002417] 0.0077383867\n",
      "19 [0.9002472] 0.0077383765\n",
      "20 [0.9002502] 0.007738374\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비\n",
    "hypot = W * x_train + b\n",
    "\n",
    "# 비용 함수(평균제곱오차(MSE))\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))\n",
    "\n",
    "# 최저 비용 학습을 위한 경사하강 알고리즘(Gradient Descent) \n",
    "gradient = tf.reduce_mean((hypot - y_train) * x_train)\n",
    "learning_rate = 0.1\n",
    "descent = W - (learning_rate * gradient) \n",
    "update = W.assign(descent) ## W = descent\n",
    "\n",
    "########## Graph 작업 완료 \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    _, weight, c = sess.run([update, W, cost])\n",
    "    print(step, weight, c)\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.7774806] 1.6618359\n",
      "1 [0.7368965] 0.17947382\n",
      "2 [0.74095494] 0.1646502\n",
      "3 [0.740549] 0.164502\n",
      "4 [0.7405896] 0.16450045\n",
      "5 [0.7405856] 0.16450049\n",
      "6 [0.740586] 0.16450052\n",
      "7 [0.7405859] 0.16450045\n",
      "8 [0.740586] 0.16450053\n",
      "9 [0.7405859] 0.16450045\n",
      "10 [0.740586] 0.16450053\n",
      "11 [0.7405859] 0.16450045\n",
      "12 [0.740586] 0.16450053\n",
      "13 [0.7405859] 0.16450045\n",
      "14 [0.740586] 0.16450053\n",
      "15 [0.7405859] 0.16450045\n",
      "16 [0.740586] 0.16450053\n",
      "17 [0.7405859] 0.16450045\n",
      "18 [0.740586] 0.16450053\n",
      "19 [0.7405859] 0.16450045\n",
      "20 [0.740586] 0.16450053\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape=[None])\n",
    "y_train = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비\n",
    "hypot = W * x_train + b\n",
    "\n",
    "# 비용 함수(평균제곱오차(MSE))\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))\n",
    "\n",
    "# 최저 비용 학습을 위한 경사하강 알고리즘(Gradient Descent) \n",
    "gradient = tf.reduce_mean((hypot - y_train) * x_train)\n",
    "learning_rate = 0.1\n",
    "descent = W - (learning_rate * gradient) \n",
    "update = W.assign(descent) ## W = descent\n",
    "\n",
    "########## Graph 작업 완료 \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    _, weight, c = sess.run([update, W, cost], feed_dict={x_train:[1, 2, 3, 4, 5], y_train:[1, 2, 3, 4, 5]})\n",
    "    print(step, weight, c)\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [2.372611] 22.672928\n",
      "1 [2.1320703] 13.340586\n",
      "2 [1.9481612] 7.9012923\n",
      "3 [1.8074846] 4.730685\n",
      "4 [1.6998119] 2.8821583\n",
      "5 [1.6173346] 1.8040829\n",
      "6 [1.554092] 1.1749926\n",
      "7 [1.5055338] 0.807556\n",
      "8 [1.4681863] 0.5926027\n",
      "9 [1.4393977] 0.4665149\n",
      "10 [1.4171438] 0.39221925\n",
      "11 [1.3998795] 0.3481109\n",
      "12 [1.3864248] 0.32160002\n",
      "13 [1.3758793] 0.30534914\n",
      "14 [1.3675556] 0.29508263\n",
      "15 [1.3609289] 0.28830916\n",
      "16 [1.3555986] 0.28357646\n",
      "17 [1.3512588] 0.28003836\n",
      "18 [1.347676] 0.27720177\n",
      "19 [1.3446721] 0.27477905\n",
      "20 [1.342111] 0.2726028\n"
     ]
    }
   ],
   "source": [
    "######### 경사하강 알고리즘 객체 사용 ##########\n",
    "\n",
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape=[None])\n",
    "y_train = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비\n",
    "hypot = W * x_train + b\n",
    "\n",
    "# 비용 함수(평균제곱오차(MSE))\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))\n",
    "\n",
    "# 최저 비용 학습을 위한 경사하강 알고리즘(Gradient Descent) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "########## Graph 작업 완료 \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    _, weight, c = sess.run([train, W, cost], feed_dict={x_train:[1, 2, 3, 4, 5], y_train:[1, 2, 3, 4, 5]})\n",
    "    print(step, weight, c)\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9014084 [1.5710166] [-1.0953137]\n",
      "100 0.44473806 [1.4314986] [-0.457847]\n",
      "200 0.2259124 [1.307537] [-0.01030603]\n",
      "300 0.11475615 [1.2191871] [0.30866453]\n",
      "400 0.058292378 [1.1562186] [0.5360008]\n",
      "500 0.02961064 [1.1113399] [0.69802743]\n",
      "600 0.015041241 [1.079354] [0.8135066]\n",
      "700 0.0076404363 [1.056557] [0.8958111]\n",
      "800 0.0038811036 [1.0403092] [0.95447063]\n",
      "900 0.0019714788 [1.0287291] [0.9962785]\n",
      "1000 0.0010014308 [1.0204757] [1.0260761]\n",
      "1100 0.0005087006 [1.0145935] [1.0473129]\n",
      "1200 0.00025840814 [1.0104012] [1.0624485]\n",
      "1300 0.00013126199 [1.007413] [1.0732365]\n",
      "1400 6.667753e-05 [1.0052835] [1.080925]\n",
      "1500 3.3871045e-05 [1.0037657] [1.0864048]\n",
      "1600 1.7207338e-05 [1.002684] [1.09031]\n",
      "1700 8.74029e-06 [1.001913] [1.0930936]\n",
      "1800 4.4405315e-06 [1.0013635] [1.0950774]\n",
      "1900 2.2559002e-06 [1.0009718] [1.0964913]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "x_train = tf.placeholder(tf.float32, shape=[None])\n",
    "y_train = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# W는 1, bias는 1.1\n",
    "W = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비\n",
    "hypot = W * x_train + b\n",
    "\n",
    "# 비용 함수(평균제곱오차(MSE))\n",
    "cost = tf.reduce_mean(tf.square(hypot - y_train))\n",
    "\n",
    "# 최저 비용 학습을 위한 경사하강 알고리즘(Gradient Descent) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "########## Graph 작업 완료 \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000):\n",
    "    _, c, weight, bias = sess.run([train, cost, W, b], feed_dict={x_train:[1, 2, 3, 4, 5], y_train:[2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 100 == 0:\n",
    "        print(step, c, weight, bias)\n",
    "\n",
    "# 1(W) * 1 + 1.1(b)= 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.116259]\n",
      "[3.5992284 4.800062 ]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "print(sess.run(hypot, feed_dict={x_train:[27]}))\n",
    "print(sess.run(hypot, feed_dict={x_train:[2.5, 3.7]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13455493000.0 [10370.845] [2081.121]\n",
      "500 8687841.0 [25537.209] [1951.7363]\n",
      "1000 8633819.0 [25627.463] [1504.8074]\n",
      "1500 8632671.0 [25640.613] [1439.6826]\n",
      "2000 8632650.0 [25642.531] [1430.1888]\n",
      "2500 8632654.0 [25642.805] [1428.8201]\n",
      "3000 8632657.0 [25642.844] [1428.633]\n"
     ]
    }
   ],
   "source": [
    "# 아래의 데이터를 가지고 하루 8시간을 일했을 때 매출액이 얼마인지 예측하시오.\n",
    "x_data = [1, 2, 3, 4, 5, 6, 7]\n",
    "y_data = [25000, 55000, 75000, 110000, 128000, 155000, 180000]\n",
    "\n",
    "# 데이터 준비\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"Weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# 가설 준비\n",
    "hypot = W * X + b\n",
    "\n",
    "# 비용 함수(평균제곱오차(MSE))\n",
    "cost = tf.reduce_mean(tf.square(hypot - y))\n",
    "\n",
    "# 최저 비용 학습을 위한 경사하강 알고리즘(Gradient Descent) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "########## Graph 작업 완료 \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3001):\n",
    "    _, c, weight, bias = sess.run([train, cost, W, b], feed_dict={X:x_data, y:y_data})\n",
    "    \n",
    "    if step % 500 == 0:\n",
    "        print(step, c, weight, bias)\n",
    "    \n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206571.39]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hypot, feed_dict={X:[8]}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다중 선형 회귀 모델(여러개의 입력(feature)의 Linear Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196., 142.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 단순하게 처리하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = tf.placeholder(tf.float32, shape=[None])\n",
    "X2 = tf.placeholder(tf.float32, shape=[None])\n",
    "X3 = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# 가설 준비(가중치, bias)\n",
    "W1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "W2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "W3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# 가설 설정\n",
    "hypot = W1*X1 + W2*X2 + W3*X3 + b\n",
    "\n",
    "# 비용 함수(비용이 얼마나 드는지 계산:예측값 - 실제값)\n",
    "# square(제곱),reduce_mean(특정 차원을 제거하고 평균\n",
    "cost = tf.reduce_mean(tf.square((hypot - y)))\n",
    "\n",
    "# 최소 비용 계산\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10365.824 [245.9485  290.14343 288.76587 314.84964 219.41063]\n",
      "500 9.758608 [155.05124 182.05153 181.65929 198.26164 137.21239]\n",
      "1000 7.6273293 [154.51651 182.42001 181.4979  198.12567 137.71219]\n",
      "1500 5.9986634 [154.05057 182.74138 181.35756 198.00522 138.1499 ]\n",
      "2000 4.7533555 [153.64467 183.02153 181.23558 197.89827 138.53339]\n",
      "2500 3.8004997 [153.29117 183.26575 181.12964 197.80316 138.86946]\n",
      "3000 3.070734 [152.98344 183.47855 181.03767 197.7184  139.16415]\n",
      "3500 2.5111854 [152.71565 183.66394 180.95795 197.64268 139.42267]\n",
      "4000 2.0815012 [152.48276 183.82541 180.88887 197.57492 139.64961]\n",
      "4500 1.750941 [152.2803  183.96597 180.82907 197.5141  139.84894]\n"
     ]
    }
   ],
   "source": [
    "# 세션 처리\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 초기화\n",
    "    \n",
    "    for step in range(5000):\n",
    "        _, c, h = sess.run([train, cost, hypot], feed_dict={X1:x1_data, X2:x2_data, X3:x3_data, y:y_data})\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print(step, c, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Matrix로 처리하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 입력\n",
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.], \n",
    "          [89., 91., 90.], \n",
    "          [96., 98., 100.], \n",
    "          [73., 66., 70.]]\n",
    "\n",
    "y_data = [[152.], \n",
    "          [185.], \n",
    "          [180.], \n",
    "          [196.], \n",
    "          [142.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[5, 1])\n",
    "\n",
    "# 가설 준비(가중치, bias)\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# 가설 설정(행렬곱으로 작성)\n",
    "hypot = tf.matmul(X, W) + b\n",
    "\n",
    "# 비용 함수\n",
    "cost = tf.reduce_mean(tf.square((hypot - y)))\n",
    "\n",
    "# 최소 비용 계산\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 20098.574 [[29.645334]\n",
      " [31.011095]\n",
      " [33.20114 ]\n",
      " [32.73211 ]\n",
      " [25.366747]]\n",
      "500 4.450091 [[155.04384]\n",
      " [182.43904]\n",
      " [182.03503]\n",
      " [194.87845]\n",
      " [140.98622]]\n",
      "1000 3.6947885 [[154.71352]\n",
      " [182.66287]\n",
      " [181.93044]\n",
      " [194.829  ]\n",
      " [141.25786]]\n",
      "1500 3.112489 [[154.42365]\n",
      " [182.85896]\n",
      " [181.83827]\n",
      " [194.78821]\n",
      " [141.49338]]\n",
      "2000 2.6622972 [[154.16914]\n",
      " [183.0308 ]\n",
      " [181.75696]\n",
      " [194.75497]\n",
      " [141.69736]]\n",
      "2500 2.3129582 [[153.94554]\n",
      " [183.18153]\n",
      " [181.68517]\n",
      " [194.72833]\n",
      " [141.87383]]\n",
      "3000 2.0407286 [[153.74898]\n",
      " [183.3138 ]\n",
      " [181.6217 ]\n",
      " [194.7074 ]\n",
      " [142.02634]]\n",
      "3500 1.8273987 [[153.576  ]\n",
      " [183.4299 ]\n",
      " [181.5655 ]\n",
      " [194.69147]\n",
      " [142.15788]]\n",
      "4000 1.6591594 [[153.42361]\n",
      " [183.53186]\n",
      " [181.51566]\n",
      " [194.6798 ]\n",
      " [142.27116]]\n",
      "4500 1.525409 [[153.28926]\n",
      " [183.62152]\n",
      " [181.47136]\n",
      " [194.67186]\n",
      " [142.3685 ]]\n",
      "[[153.1709 ]\n",
      " [183.70026]\n",
      " [181.43204]\n",
      " [194.66716]\n",
      " [142.45181]]\n"
     ]
    }
   ],
   "source": [
    "# 세션 처리\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer()) # 초기화\n",
    "    \n",
    "    for step in range(5000):\n",
    "        _, c, h = sess.run([train, cost, hypot], feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "        if step % 500 == 0:\n",
    "            print(step, c, h)\n",
    "    \n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DASK\n",
    "\n",
    "+ 가상의 데이터프레임\n",
    "+ 병렬 처리용 작업 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/sample1.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"data/sample1.csv\"\n",
    "c1, c2, c3\n",
    "1, 1.11, one\n",
    "2, 2.22, two\n",
    "3, 3.33, three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.22"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/sample1.csv\")\n",
    "df1\n",
    "df1[\" c2\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 1 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                  c1       c2      c3\n",
       "npartitions=1                        \n",
       "               int64  float64  object\n",
       "                 ...      ...     ...\n",
       "Dask Name: read-csv, 1 tasks"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = dd.read_csv(\"data/sample1.csv\")\n",
    "df2\n",
    "\n",
    "# 메타 정보만 불러와서 정보만 제공, 실제 데이터는 존재하지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\dask\\dataframe\\core.py:6194: UserWarning: Insufficient elements for `head`. 5 elements requested, only 3 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2.22</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1    c2      c3\n",
       "0   1  1.11     one\n",
       "1   2  2.22     two\n",
       "2   3  3.33   three"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.22"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[\" c2\"].mean().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>Beat</th>\n",
       "      <th>District</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>FBI Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Historical Wards 2003-2015</th>\n",
       "      <th>Zip Codes</th>\n",
       "      <th>Community Areas</th>\n",
       "      <th>Census Tracts</th>\n",
       "      <th>Wards</th>\n",
       "      <th>Boundaries - ZIP Codes</th>\n",
       "      <th>Police Districts</th>\n",
       "      <th>Police Beats</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=7</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 7 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   ID Case Number    Date   Block    IUCR Primary Type Description Location Description  Arrest Domestic    Beat District    Ward Community Area FBI Code X Coordinate Y Coordinate    Year Updated On Latitude Longitude Location Historical Wards 2003-2015 Zip Codes Community Areas Census Tracts   Wards Boundaries - ZIP Codes Police Districts Police Beats\n",
       "npartitions=7                                                                                                                                                                                                                                                                                                                                                                     \n",
       "               object      object  object  object  object       object      object               object  object   object  object   object  object         object   object       object       object  object     object   object    object   object                     object    object          object        object  object                 object           object       object\n",
       "                  ...         ...     ...     ...     ...          ...         ...                  ...     ...      ...     ...      ...     ...            ...      ...          ...          ...     ...        ...      ...       ...      ...                        ...       ...             ...           ...     ...                    ...              ...          ...\n",
       "...               ...         ...     ...     ...     ...          ...         ...                  ...     ...      ...     ...      ...     ...            ...      ...          ...          ...     ...        ...      ...       ...      ...                        ...       ...             ...           ...     ...                    ...              ...          ...\n",
       "                  ...         ...     ...     ...     ...          ...         ...                  ...     ...      ...     ...      ...     ...            ...      ...          ...          ...     ...        ...      ...       ...      ...                        ...       ...             ...           ...     ...                    ...              ...          ...\n",
       "                  ...         ...     ...     ...     ...          ...         ...                  ...     ...      ...     ...      ...     ...            ...      ...          ...          ...     ...        ...      ...       ...      ...                        ...       ...             ...           ...     ...                    ...              ...          ...\n",
       "Dask Name: read-csv, 7 tasks"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = dd.read_csv(\"data/crime.csv\", dtype=str, error_bad_lines=False, warn_bad_lines=False)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                            1691927\n",
       "Case Number                   1691927\n",
       "Date                          1691927\n",
       "Block                         1691927\n",
       "IUCR                          1691927\n",
       "Primary Type                  1691927\n",
       "Description                   1691927\n",
       "Location Description          1687412\n",
       "Arrest                        1691927\n",
       "Domestic                      1691927\n",
       "Beat                          1691927\n",
       "District                      1691926\n",
       "Ward                          1691909\n",
       "Community Area                1691924\n",
       "FBI Code                      1691927\n",
       "X Coordinate                  1673496\n",
       "Y Coordinate                  1673496\n",
       "Year                          1691927\n",
       "Updated On                    1691927\n",
       "Latitude                      1673496\n",
       "Longitude                     1673496\n",
       "Location                      1673496\n",
       "Historical Wards 2003-2015    1668258\n",
       "Zip Codes                     1673496\n",
       "Community Areas               1669046\n",
       "Census Tracts                 1669537\n",
       "Wards                         1669074\n",
       "Boundaries - ZIP Codes        1669069\n",
       "Police Districts              1669256\n",
       "Police Beats                  1669264\n",
       "dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()\n",
    "df3.tail()\n",
    "df3.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 표시기 (tqdm 비슷한거)\n",
    "from dask.diagnostics import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "pbar.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 25.8s\n",
      "[########################################] | 100% Completed | 25.8s\n",
      "Wall time: 26 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                            1691927\n",
       "Case Number                   1691927\n",
       "Date                          1691927\n",
       "Block                         1691927\n",
       "IUCR                          1691927\n",
       "Primary Type                  1691927\n",
       "Description                   1691927\n",
       "Location Description          1687412\n",
       "Arrest                        1691927\n",
       "Domestic                      1691927\n",
       "Beat                          1691927\n",
       "District                      1691926\n",
       "Ward                          1691909\n",
       "Community Area                1691924\n",
       "FBI Code                      1691927\n",
       "X Coordinate                  1673496\n",
       "Y Coordinate                  1673496\n",
       "Year                          1691927\n",
       "Updated On                    1691927\n",
       "Latitude                      1673496\n",
       "Longitude                     1673496\n",
       "Location                      1673496\n",
       "Historical Wards 2003-2015    1668258\n",
       "Zip Codes                     1673496\n",
       "Community Areas               1669046\n",
       "Census Tracts                 1669537\n",
       "Wards                         1669074\n",
       "Boundaries - ZIP Codes        1669069\n",
       "Police Districts              1669256\n",
       "Police Beats                  1669264\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df3.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask 작업 스케줄러를 이용해 병렬처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 25.0s\n",
      "[########################################] | 100% Completed | 25.0s\n",
      "Wall time: 25.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID                            1691927\n",
       "Case Number                   1691927\n",
       "Date                          1691927\n",
       "Block                         1691927\n",
       "IUCR                          1691927\n",
       "Primary Type                  1691927\n",
       "Description                   1691927\n",
       "Location Description          1687412\n",
       "Arrest                        1691927\n",
       "Domestic                      1691927\n",
       "Beat                          1691927\n",
       "District                      1691926\n",
       "Ward                          1691909\n",
       "Community Area                1691924\n",
       "FBI Code                      1691927\n",
       "X Coordinate                  1673496\n",
       "Y Coordinate                  1673496\n",
       "Year                          1691927\n",
       "Updated On                    1691927\n",
       "Latitude                      1673496\n",
       "Longitude                     1673496\n",
       "Location                      1673496\n",
       "Historical Wards 2003-2015    1668258\n",
       "Zip Codes                     1673496\n",
       "Community Areas               1669046\n",
       "Census Tracts                 1669537\n",
       "Wards                         1669074\n",
       "Boundaries - ZIP Codes        1669069\n",
       "Police Districts              1669256\n",
       "Police Beats                  1669264\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df3.count().compute(scheduler=\"processes\", num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.2s\n",
      "Wall time: 238 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    5\n",
       "2    6\n",
       "Name: c1, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "(df2[\"c1\"] + 3).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 특정 컬럼 수정\n",
    "\n",
    "# 오류\n",
    "#c1 = df2[\"c1\"]-3\n",
    "#df2 = c1\n",
    "\n",
    "# 데이터 프레임을 시리즈로 변경\n",
    "# df2 = df2[\"c1\"]-3  --> 기존 컬럼 다 삭제되고 시리즈가 됨. 즉, assign을 사용 할 수 없음\n",
    "\n",
    "df2 = df2.assign(c1 = df2[\"c1\"]-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\dask\\dataframe\\core.py:6194: UserWarning: Insufficient elements for `head`. 5 elements requested, only 3 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.22</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1    c2      c3\n",
       "0  -2  1.11     one\n",
       "1  -1  2.22     two\n",
       "2   0  3.33   three"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 새로운 컬럼 추가\n",
    "df2 = df2.assign(title=df2[\"c1\"].astype(str) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.1s\n",
      "[########################################] | 100% Completed |  0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\dask\\dataframe\\core.py:6194: UserWarning: Insufficient elements for `head`. 5 elements requested, only 3 elements available. Try passing larger `npartitions` to `head`.\n",
      "  warnings.warn(msg.format(n, len(r)))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2</td>\n",
       "      <td>1.11</td>\n",
       "      <td>one</td>\n",
       "      <td>-2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>2.22</td>\n",
       "      <td>two</td>\n",
       "      <td>-1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>three</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   c1    c2      c3 title\n",
       "0  -2  1.11     one   -2%\n",
       "1  -1  2.22     two   -1%\n",
       "2   0  3.33   three    0%"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data/sample2.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"data/sample2.csv\"\n",
    "c1, c2, c3\n",
    "4, 4.11, one\n",
    "5, 5.22, two\n",
    "6, 6.33, three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = dd.read_csv(\"data/sample*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  0.2s\n",
      "[########################################] | 100% Completed |  0.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "c1     6\n",
       " c2    6\n",
       " c3    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.count().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QueueRunner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-878b3591e2fa>:9: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "4.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "q = tf.FIFOQueue(20, \"float\") #queue의 길이와 저장될 데이터 형식\n",
    "#enq_ops = q.enqueue_many(([1.0, 2.0, 3.0, 4.0],))\n",
    "#qr = tf.train.QueueRunnder(q, [enq_ops]*3)\n",
    "#qr = tf.train.QueueRunner(q, [enq_ops, enq_ops, enq_ops])\n",
    "\n",
    "enq_ops1 = q.enqueue_many(([1.0, 2.0, 3.0],))\n",
    "enq_ops2 = q.enqueue_many(([4.0, 5.0, 6.0],))\n",
    "enq_ops3 = q.enqueue_many(([7.0, 8.0, 9.0],))\n",
    "qr = tf.train.QueueRunner(q, [enq_ops1, enq_ops2, enq_ops3])\n",
    "\n",
    "# 세션 객체 생성\n",
    "sess = tf.Session()\n",
    "# 코디네이터(관리자) 생성\n",
    "coordi = tf.train.Coordinator()\n",
    "# 스레드 생성\n",
    "threads = qr.create_threads(sess, coord=coordi, start=True)\n",
    "\n",
    "for step in range(20):\n",
    "    print(sess.run(q.dequeue()))\n",
    "    \n",
    "coordi.request_stop() \n",
    "coordi.join(threads) # 스레드가 동시에 작동하기 위함\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1.11, b' one']\n",
      "[2, 2.22, b' two']\n",
      "[3, 3.33, b' three']\n",
      "[4, 4.11, b' one']\n",
      "[5, 5.22, b' two']\n",
      "[6, 6.33, b' three']\n",
      "[1, 1.11, b' one']\n",
      "[2, 2.22, b' two']\n",
      "[3, 3.33, b' three']\n",
      "[4, 4.11, b' one']\n",
      "[5, 5.22, b' two']\n",
      "[6, 6.33, b' three']\n",
      "[1, 1.11, b' one']\n",
      "[2, 2.22, b' two']\n",
      "[3, 3.33, b' three']\n",
      "[4, 4.11, b' one']\n",
      "[5, 5.22, b' two']\n",
      "[6, 6.33, b' three']\n",
      "[1, 1.11, b' one']\n",
      "[2, 2.22, b' two']\n",
      "[3, 3.33, b' three']\n",
      "[4, 4.11, b' one']\n",
      "[5, 5.22, b' two']\n",
      "[6, 6.33, b' three']\n",
      "[1, 1.11, b' one']\n",
      "[2, 2.22, b' two']\n",
      "[3, 3.33, b' three']\n",
      "[4, 4.11, b' one']\n",
      "[5, 5.22, b' two']\n",
      "[6, 6.33, b' three']\n"
     ]
    }
   ],
   "source": [
    "########## 파일로 부터 데이터를 읽어오기 ##########\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"data/sample1.csv\", \"data/sample2.csv\"], \n",
    "                                                shuffle=False, name=\"filename_queue\")\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "recored_defaults = [[10], [0.0], [\"null\"]] # 각 컬럼의 디폴트값 설정\n",
    "# decording\n",
    "c1, c2, c3 = tf.decode_csv(value, record_defaults=recored_defaults, field_delim=\",\")\n",
    "## 그래프 작업 끝 ##\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    coordi = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordi)\n",
    "    \n",
    "    for i in range(30):\n",
    "        print(sess.run([c1, c2, c3]))\n",
    "        \n",
    "    coordi.request_stop()\n",
    "    coordi.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'DecodeCSV_5:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'DecodeCSV_5:1' shape=() dtype=float32>,\n",
       " <tf.Tensor 'DecodeCSV_5:2' shape=() dtype=float32>,\n",
       " <tf.Tensor 'DecodeCSV_5:3' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## 슬라이드 소스 ##########\n",
    "\n",
    "filename_queue = tf.train.string_input_producer([\"data/data-01-test-score1.csv\"])\n",
    "key, value = tf.TextLineReader().read(filename_queue)\n",
    "xy = tf.decode_csv(value, record_defaults=[[0.], [0.], [0.], [0.]])\n",
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BATCH : 모아두었다가 일괄처리\n",
    "--------\n",
    "- Batch : 전체 데이터(데이터가 너무 크면 무용지물)\n",
    "- Stochastic : 한개의 데이터(데이터를 한개씩 꺼내오기, 만일 데이터가 100개면 백번, 속도가 빠름)\n",
    "- Mini Batch : Batch와 Stochastic의 절충안 (덩어리로 쪼개서 반복, 100개를 20개씩 묶어서 다섯번 처리)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-7a3ccde6dd8b>:1: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "train_x_batch, train_y_batch = tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "# x값: xy[0:-1]0부터 맨 뒤 바로 앞까지, y값: xy[-1:]민 뒤 바로 앞에서 끝까지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 그래프 그리기 ###\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# 가설 설정(행렬곱)\n",
    "hypot = tf.matmul(X, W) + b\n",
    "cost = tf.reduce_mean(tf.square(hypot-y))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "당신의 성적은 :  [[185.46649]]\n",
      "다른 사람의 성적은 :  [[161.51276]\n",
      " [181.83   ]]\n"
     ]
    }
   ],
   "source": [
    "### 실행 ###\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    coordi = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordi)\n",
    "    \n",
    "    for step in range(2001):\n",
    "        x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "        sess.run(train, feed_dict={X:x_batch, y:y_batch})  #10개씩 끊어서 값을 리턴\n",
    "        \n",
    "    coordi.request_stop()\n",
    "    coordi.join(threads)\n",
    "    \n",
    "    print(\"당신의 성적은 : \", sess.run(hypot, feed_dict={X:[[100, 70, 101]]}))\n",
    "    print(\"다른 사람의 성적은 : \", sess.run(hypot, feed_dict={X:[[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "전체 데이터갯수 : 200\n",
    "batch_size : 5\n",
    "ephoch의 갯수 : 1000\n",
    "총 가중치의 업데이트 횟수 : 4000(200/5=40, 40*1000=4000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 로지스틱 회귀 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "\n",
    "X =tf.placeholder(tf.float32, shape=[None, 2])\n",
    "y =tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "# 가설\n",
    "hypot = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용 함수\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(10001):\n",
    "    sess.run(train, feed_dict={X:x_data, y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 측정\n",
    "pred = tf.cast(hypot > 0.5, dtype=tf.float32) # 데이터 형식 변경(bool->실수)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.03409758],\n",
       "        [0.16316158],\n",
       "        [0.32054812],\n",
       "        [0.7743075 ],\n",
       "        [0.9350291 ],\n",
       "        [0.97865534]], dtype=float32),\n",
       " array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], dtype=float32),\n",
       " 1.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 실행\n",
    "sess.run([hypot, pred, accuracy], feed_dict={X:x_data, y:y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda clearn --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1], [2, 1, 3, 2], [3, 1, 3, 4], [4, 1, 5, 5], [1, 7, 5, 5], [1, 2, 5, 6], [1, 6, 6, 6], [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1], [0, 0, 1], [0, 0, 1], [0, 1, 0], [0, 1, 0], [0, 1, 0], [1, 0, 0], [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# 가설 준비(다중분류)\n",
    "hypot = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# 비용 함수\n",
    "cost = -tf.reduce_mean(y * tf.log(hypot) + (1 - y) * tf.log(1 - hypot))\n",
    "\n",
    "# 최소비용\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 준비\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # 훈련시작    \n",
    "    for step in range(5001):\n",
    "        _, c = sess.run([train, cost], feed_dict={X:x_data, y:y_data})\n",
    "        #if step%500 == 0:\n",
    "        #    print(step, c)\n",
    "        \n",
    "    # 테스트\n",
    "    result = sess.run(hypot, feed_dict={X:[[1, 11, 7, 9]]})\n",
    "    print(result)\n",
    "    print(sess.run(tf.arg_max(result, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fancy Softmax : softmax_cross_entropy_with_logits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.5960515e-04 9.9973959e-01 8.8786646e-07]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "W = tf.Variable(tf.random_normal([4, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# 가설 준비\n",
    "logit = tf.matmul(X, W) + b\n",
    "hypot = tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y_data)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "       \n",
    "    for step in range(5001):\n",
    "        _, c = sess.run([train, cost], feed_dict={X:x_data, y:y_data})\n",
    "        #if step%500 == 0:\n",
    "        #    print(step, c)\n",
    "        \n",
    "    # 테스트\n",
    "    result = sess.run(hypot, feed_dict={X:[[1, 11, 7, 9]]})\n",
    "    print(result)\n",
    "    print(sess.run(tf.arg_max(result, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0.]],\n",
       "\n",
       "       [[0., 1., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eval() 사용법\n",
    "sess = tf.Session()\n",
    "#one = tf.one_hot([[0], [1], [2], [0], [1], [1]], depth=3)\n",
    "tf.one_hot([[0], [1], [2], [0], [1], [1]], depth=3).eval(session=sess)\n",
    "\n",
    "#sess.run(one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례1 : 동물 분류 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 17)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = np.loadtxt(\"data/data-04-zoo.csv\", delimiter=\",\", dtype=np.float32)\n",
    "xy\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 16])\n",
    "y = tf.placeholder(tf.int32, shape=[None, 1])\n",
    "\n",
    "y_onehot = tf.one_hot(y, 7)\n",
    "#print(y_onehot.eval(session=sess, feed_dict={y:y_data}))\n",
    "\n",
    "# 차원 조정\n",
    "y_onehot = tf.reshape(y_onehot, [-1, 7])\n",
    "#print(y_onehot.eval(session=sess, feed_dict={y:y_data}))\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, 7]))\n",
    "b = tf.Variable(tf.random_normal([7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = tf.matmul(X, W) + b\n",
    "hypot = tf.nn.softmax(logit)\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y_onehot)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost) #최소비용\n",
    "##### 모델만들기 끝 #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값\n",
    "pred = tf.argmax(hypot, 1)\n",
    "correct = tf.equal(pred, tf.argmax(y_onehot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.126278 0.4059406\n",
      "3.5626166 0.84158415\n",
      "0.14190337 0.97029704\n",
      "0.01213748 1.0\n",
      "0.00902386 1.0\n",
      "0.007564456 1.0\n",
      "0.006604456 1.0\n",
      "0.0058995304 1.0\n",
      "0.005351655 1.0\n",
      "0.00490982 1.0\n"
     ]
    }
   ],
   "source": [
    "# 초기화, 값 구하기1\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    sess.run(train, feed_dict={X:x_data, y:y_data})\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        c, a = sess.run([tf.reduce_mean(cost), accuracy], feed_dict={X:x_data, y:y_data})\n",
    "        \n",
    "        print(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.744424 0.36633664\n",
      "6.21799 0.84158415\n",
      "0.16847663 0.95049506\n",
      "0.4045867 0.9405941\n",
      "0.008624465 1.0\n",
      "0.005031875 1.0\n",
      "0.004054469 1.0\n",
      "0.0035448717 1.0\n",
      "0.0032046048 1.0\n",
      "0.0029492155 1.0\n"
     ]
    }
   ],
   "source": [
    "# 초기화, 값 구하기2\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    _, c, a = sess.run([train, tf.reduce_mean(cost), accuracy], feed_dict={X:x_data, y:y_data})\n",
    "    \n",
    "    if step%10 == 0:\n",
    "        print(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 3 \t 3\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 3 \t 3\n",
      "True \t 3 \t 3\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 3 \t 3\n",
      "True \t 6 \t 6\n",
      "True \t 6 \t 6\n",
      "True \t 6 \t 6\n",
      "True \t 1 \t 1\n",
      "True \t 0 \t 0\n",
      "True \t 3 \t 3\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 1 \t 1\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 5 \t 5\n",
      "True \t 4 \t 4\n",
      "True \t 4 \t 4\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 5 \t 5\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 3 \t 3\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 3 \t 3\n",
      "True \t 5 \t 5\n",
      "True \t 5 \t 5\n",
      "True \t 1 \t 1\n",
      "True \t 5 \t 5\n",
      "True \t 1 \t 1\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 6 \t 6\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 5 \t 5\n",
      "True \t 4 \t 4\n",
      "True \t 6 \t 6\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 1 \t 1\n",
      "True \t 1 \t 1\n",
      "True \t 1 \t 1\n",
      "True \t 3 \t 3\n",
      "True \t 3 \t 3\n",
      "True \t 2 \t 2\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 6 \t 6\n",
      "True \t 3 \t 3\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 2 \t 2\n",
      "True \t 6 \t 6\n",
      "True \t 1 \t 1\n",
      "True \t 1 \t 1\n",
      "True \t 2 \t 2\n",
      "True \t 6 \t 6\n",
      "True \t 3 \t 3\n",
      "True \t 1 \t 1\n",
      "True \t 0 \t 0\n",
      "True \t 6 \t 6\n",
      "True \t 3 \t 3\n",
      "True \t 1 \t 1\n",
      "True \t 5 \t 5\n",
      "True \t 4 \t 4\n",
      "True \t 2 \t 2\n",
      "True \t 2 \t 2\n",
      "True \t 3 \t 3\n",
      "True \t 0 \t 0\n",
      "True \t 0 \t 0\n",
      "True \t 1 \t 1\n",
      "True \t 0 \t 0\n",
      "True \t 5 \t 5\n",
      "True \t 0 \t 0\n",
      "True \t 6 \t 6\n",
      "True \t 1 \t 1\n"
     ]
    }
   ],
   "source": [
    "pred1 = sess.run(pred, feed_dict={X:x_data})\n",
    "pred1\n",
    "\n",
    "for p, y in zip(pred1, y_data.flatten()): # .flatten()/ravel()-1차원으로 맞춘 후 비교\n",
    "    #print(p, y)\n",
    "    print(p==int(y), \"\\t\", p, \"\\t\", int(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사례2 : MNIST 손글씨 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-f303c6bf2c90>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mnist)\n",
    "dir(mnist)\n",
    "mnist.train.labels\n",
    "mnist.train.num_examples\n",
    "mnist.test.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 28*28])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([28*28, 10]))\n",
    "b = tf.Variable(tf.random_normal([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = tf.matmul(X, W) + b\n",
    "hypot = tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=y)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(hypot, 1), tf.argmax(y, 1)) # equal(예측값, 실제값)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4503819402781413 \t 0.94\n",
      "2.210745538202198 \t 0.87\n",
      "1.953576785867864 \t 0.82\n",
      "1.862582359937103 \t 0.85\n",
      "1.9064367469603365 \t 0.88\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# for step in range(200):\n",
    "#     _, c, a = sess.run([train, tf.reduce_mean(cost), accuracy], feed_dict={X:mnist.train.images, y:mnist.train.labels})\n",
    "    \n",
    "#     if step%20 == 0:\n",
    "#         print(c, \"\\t\", a)\n",
    "\n",
    "# mini batch: 데이터 쪼개기\n",
    "training_epochs = 5\n",
    "batch_size = 100\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)  # next(): 값 2개씩 리턴\n",
    "        \n",
    "        _, c, a = sess.run([train, tf.reduce_mean(cost), accuracy], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        \n",
    "        avg_cost += c / total_batch\n",
    "        \n",
    "    print(avg_cost, \"\\t\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 :  0.8749\n"
     ]
    }
   ],
   "source": [
    "# 정확도 확인\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5376"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "r = random.randint(0, mnist.test.num_examples-1)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  [5]\n"
     ]
    }
   ],
   "source": [
    "print(\"label : \", sess.run(tf.argmax(mnist.test.labels[r:r+1], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction :  [5]\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction : \", sess.run(tf.argmax(hypot, 1), feed_dict={X:mnist.test.images[r:r+1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27fcd664cc8>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.test.images[r:r+1].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
