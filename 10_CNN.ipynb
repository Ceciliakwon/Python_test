{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 샘플1 : 3 * 3 * 1 * 1 이미지 준비, 2 * 2 * 1 필터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3*3크기, 1:색상(흑백), 1장의 이미지/ 2*2크기, 1필터의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x195d03464c8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = np.array([[[[1], [2], [3]], \n",
    "                   [[4], [5], [6]], \n",
    "                   [[7], [8], [9]]]], dtype=np.float32)\n",
    "image.shape\n",
    "plt.imshow(image.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n",
      "[[12. 16.]\n",
      " [24. 28.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# padding없이 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[1.]], [[1.]]], \n",
    "                      [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)  # 축 변경\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(2, 2))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(2, 2), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 1)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# padding을 이용한 convolution layer 추출\n",
    "\n",
    "filter = tf.constant([[[[1.]], [[1.]]], \n",
    "                      [[[1.]], [[1.]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)  # 축 변경\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 3, 3)\n",
      "[[12. 16.  9.]\n",
      " [24. 28. 15.]\n",
      " [15. 17.  9.]]\n",
      "[[120. 160.  90.]\n",
      " [240. 280. 150.]\n",
      " [150. 170.  90.]]\n",
      "[[-12. -16.  -9.]\n",
      " [-24. -28. -15.]\n",
      " [-15. -17.  -9.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3개의 필터 사용(2*2*1*3)\n",
    "\n",
    "filter = tf.constant([[[[1., 10, -1]], [[1., 10, -1]]], \n",
    "                      [[[1., 10, -1]], [[1., 10, -1]]]])\n",
    "filter.shape\n",
    "conv2d = tf.nn.conv2d(image, filter, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "conv2d_img = sess.run(conv2d)\n",
    "print(conv2d_img.shape)\n",
    "\n",
    "conv2d_img = np.swapaxes(conv2d_img, 0, 3)  # 축 변경\n",
    "for i, one_img in enumerate(conv2d_img):\n",
    "    print(one_img.reshape(3, 3))\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(one_img.reshape(3, 3), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1)\n",
      "[[[[4]]]]\n"
     ]
    }
   ],
   "source": [
    "# MaxPooling(2*2)\n",
    "\n",
    "image2 = tf.constant([[[[4], [3]],\n",
    "                      [[2], [1]]]])\n",
    "\n",
    "pool = tf.nn.max_pool(image2, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding=\"VALID\")\n",
    "\n",
    "sess = tf.Session()\n",
    "p = sess.run(pool)\n",
    "print(p.shape)\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST를 이용한 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-91728e189d13>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x195d2a3be08>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPkAAAD3CAYAAADfRfLgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANa0lEQVR4nO3dbYxc5XnG8evCL7uxeVlTjEEQcDANbahQaRYcIAQnUIgcqCoCLU0Bf3BZ6kSVKit8IFUaJRaNauSKtBTSRUmltAJCTAnQFCnCkWOLkpClUoprCEWKcSwDNotJHMdd77J3P+w4Wps9Z9ZnXvfe/0+yxJl7njO3D772mT1nzjyOCAHI67hONwCgtQg5kBwhB5Ij5EByhBxIbm47XmS+e6JXC9vxUsCstV/73oyIxUc/3paQ92qhlvvKdrwUMGs9HRtfnerxym/Xba+z/X3bz9g+v3prAFqpUshtXy5pSURcIel2SXc3tSsATVN1Jr9a0kOSFBHbJJ189BNsD9gesj00qpEGWgTQiKohP1XS3knbY7aP2FdEDEZEf0T0z1NP5QYBNKZqyH8uadGk7fGIGG9CPwCarGrIt0q6QZJsf0DSrqZ1BKCpql5C+46klba3StqviZNvALpQpZDX3pqvaXIvAFqAj7UCyRFyIDlCDiRHyIHkCDmQHCEHkiPkQHKEHEiOkAPJEXIgOUIOJEfIgeQIOZAcIQeSI+RAcoQcSI6QA8kRciA5Qg4kR8iB5Ag5kBwhB5Ij5EByhBxIjpADyRFyIDlCDiRHyIHkCDmQHCEHkqu6PrlsvyBpuLY5GBEPNqclAM1UOeSS3oiIq5rWCYCWaOTt+njTugDQMpVCbnuhpGW2t9h+xPZ7p3jOgO0h20OjGmm4UQDVVAp5RByIiGUR8RFJD0jaMMVzBiOiPyL656mn0T4BVFR1Jp8zaXNvk3oB0AJVT7yda/vrkg7V/qxpXksAmqlSyCPiJ5Iua3IvAFqAD8MAyRFyIDlCDiRHyIHkCDmQHCEHkmvkBhV02GtrLy2sOcrH9g6XP2Hfb5WPP/3Zd8r3/+Rz5TtA2zCTA8kRciA5Qg4kR8iB5Ag5kBwhB5Ij5EByM/46+Z7PFF8rlqS3LxgtrT929b3NbKetfnv+jyqP/b8YK62fdNx7Sut7bjlQWt/998X/tP7u9d8vHTv8RyeW1sd+tqu0jiMxkwPJEXIgOUIOJEfIgeQIOZAcIQeSI+RAcjPiOvnLD1xUWHtp5VdKx/Z4Xp29z87VXeofl3KnzllYp15c+8bZW0rH3vzNFaX1fZ86q7Q+tmNnaX22YSYHkiPkQHKEHEiOkAPJEXIgOUIOJEfIgeRmxHXy+z/6jcJaveu9fzv8m6X1PYdOqNRTM/zb8x8srZ/1pNvUybHbdWX5/LB+5YOFtU8e/4vSsf+6dHNp/eYHV5TW9/3xmYW12Xgvet2Z3PZi23fZXlfbPs/2JtvP2L679S0CaMR03q5vkDQi6fCUeY+k1RFxmaSltpe3qDcATVA35BFxq6QtkmR7rqTeiNhRKz8q6ZKWdQegYcd64m2xpOFJ28OSFk31RNsDtodsD41qpGp/ABp0rCF/W1LfpO1FkvZO9cSIGIyI/ojonzdLbwIBusExhTwiDkrqsX1G7aHrJW1qelcAmqbKJbS1kjbaHpH0RES82OSeADSRI+osZN0EJ/rkWO4rK4/3B88vrL35u+Xf0X3qt39SWn9n+K1KPaHccRcUL3B+7cPPlI79TN/PGnrt8762prC29PPPNrTvbvZ0bHw+IvqPfpxPvAHJEXIgOUIOJEfIgeQIOZAcIQeSmxGX0JDL8G3ltzsMffH+hvb//Mihwtrn3ndxQ/vuZlxCA2YpQg4kR8iB5Ag5kBwhB5Ij5EByhBxIjpADyRFyIDlCDiRHyIHkCDmQHCEHkiPkQHKEHEhuRixdjJln1+cuLayNX7i/pa+9ZE7x/eRjHytfLnru955vdjsdx0wOJEfIgeQIOZAcIQeSI+RAcoQcSI6QA8lxnXwGm3vO0sLaK6tPLx17302DTe7mSCt6/6uwNsetnVvOnHt8YW3wn79SOvbTZ3+42e10XN2jbXux7btsr6tt32J7u+3Ntr/b+hYBNGI6M/kGSa9IWlDb7pN0Z0Q83qqmADRP3Zk8Im6VtGXSQ32S9rWqIQDNVeWXo7mS1tveanug6Em2B2wP2R4a1Uj1DgE05JhDHhFfiIgPSbpG0o22zy943mBE9EdE/zz1NNongIqOOeS2D/8ef1DSfkmtXxYVQGVVLqF92fbFtbGPRcT2JvcEoImmFfKI2Cxpc+2/72hhP7PKL29cXlrf+3vlb7S+dP3DhbWbTuj0udHu/JzVVU//ZWn9/RpqTyNt1J3/JwA0DSEHkiPkQHKEHEiOkAPJEXIgOW41bYAvnPLDfr/Wd+9rpfX/WHp/ab2Vt2R++0Dx7ZiStO3gmQ3t/9/XryiszRkp//zUqi89WVofOGl3lZYkSfNfn1d57EzFTA4kR8iB5Ag5kBwhB5Ij5EByhBxIjpADyXGdvI5Xv1i8BO/nb/pm6dg/PWG4tL5z7Fel9ZcOLSqt/8VDf1ZYW/CaS8eevvnN0vo7218urddzkn5Qeez/3rmkzs7Lr5P/dPSXhbWljxfXsmImB5Ij5EByhBxIjpADyRFyIDlCDiRHyIHkuE5eR99Fewpr9a6DX7n9D0rro/9wWmn9PY8/V1pfqmdL62XeqTyyceNXXFha/8O+r9XZQ/nc9Nb4/OLicy/U2Xc+zORAcoQcSI6QA8kRciA5Qg4kR8iB5Ag5kBzXyev4jdXF9x+fu3ZN6dhld5Rfx56rnZV6mun2vb+3tH5Zb2Nzz8C2mwtrp6ix++Rnoroht90n6auSTtPEzL9K0nxJ90nqlfSfrFkOdK/pzOQLJK2NiN22PyHps5LOkbQ6InbY/pbt5RHxw5Z2CqCSuu+LImJ3RBz+vp19kkYk9UbEjtpjj0q6pDXtAWjUtH/5sX2GJmbxDZImf2h7WNK7vozM9oDtIdtDoxppuFEA1UzrxJvtayVdJ+k2Sb+S1DepvEjS3qPHRMSgpEFJOtEnl69wB6Bl6s7kti+QdF1E3B4RwxFxUFJPbWaXpOslbWplkwCqm85M/nFJl9veXNveKWmtpI22RyQ9EREvtqi/jht77fXC2rI7imsoNnzRWEPjXzxU/lXWJ9x3UkP7z6ZuyCNivaT1U5Q42QbMAHziDUiOkAPJEXIgOUIOJEfIgeQIOZAct5qiJa7Z9ovC2mN9/1hndMlXKkta9T+rSuuLnvpRnf3PLszkQHKEHEiOkAPJEXIgOUIOJEfIgeQIOZAc18nREjec+N+FtQXHHV869uXRA6X1Bff2VWlp1mImB5Ij5EByhBxIjpADyRFyIDlCDiRHyIHkuE6OSvZ8+tLS+pI5xfd0/3S0eDloSfqTvylfJPeUp8qXhMaRmMmB5Ag5kBwhB5Ij5EByhBxIjpADyRFyIDmuk2NK7ukprX/yz79XWt8/fqiwtvK5NaVjz/onroM3U92Q2+6T9FVJp2li5l8l6cOS7pS0R9KhiLi6hT0CaMB0ZvIFktZGxG7bn5D0WUkvSbozIh5vaXcAGlY35BGxe9LmPkkHJPVJ+nHZONsDkgYkqVcLqncIoCHTPvFm+wxNzOL3aOKHw3rbW2thfpeIGIyI/ojon6fy3+8AtM60Qm77Wkl/Lem2iNgdEV+IiA9JukbSjbbPb2WTAKqbzom3CyRdFxG3T3psbkSMSTooab+kaF2LABoxnRNvH5d0ue3Nte2dkt6wfXFt/GMRsb1F/aFTxst/bv/Lkx8trT/14xWFtbMe+UGFhlDVdE68rZe0vg29AGgBPvEGJEfIgeQIOZAcIQeSI+RAcoQcSI5bTTGlGC2+VVSSlv4Vt4POFMzkQHKEHEiOkAPJEXIgOUIOJEfIgeQIOZCcI1r/fQ+290p6ddJDp0h6s+UvXA29VdOtvXVrX1Lzezs7IhYf/WBbQv6uF7WHIqK/7S88DfRWTbf21q19Se3rjbfrQHKEHEiuUyEf7NDrTge9VdOtvXVrX1KbeuvI7+QA2oe360ByhBxIru0ht73O9vdtP9NtK6/YfsH25tqfT3W4l8W277K9rrZ9nu1NteN2d5f1dovt7bXj9t0O9tVn++FaH1tsv69bjltBb205bm390gjbl0taEhFX2P4dSXdLWtnOHup4IyKu6nQTNRskvSL9erXIeyStjogdtr9le3lE/LBLeutTd6xyO9UKvOeoO45bx1YHbvdMfrWkhyQpIrZJOrnNr1/PeKcbOCwibpW0RZpYlkpSb0TsqJUflXRJh1o7oreaPk2seNtRtXX6Dq/Cu0/SiLrkuE3R2+HVgVt+3Nod8lMl7Z20PWa7K84L2F4oaVntrdQjtt/b6Z4mWSxpeNL2sKRFHeplKnVXuW2nSSvwblCXHbdjXR24GdodsJ/ryIM8HhFdMXtGxIGIWBYRH5H0gCb+gXSLtzXxU/+wRTryh2VHddMqt5NX4JX0lrrouHVqdeB2h3yrpBskyfYHJO1q8+sXsj1n0mbXBEiSIuKgpJ7aLCBJ10va1MGWjlD7dULq8Cq3k1fgjYjhbjpuR/dWe6wtx63d39b6HUkrbW/VxF/q9jrPb6dzbX9d0qHanzUd7udoayVttD0i6YmIeLHTDU3y5S5Z5XaqFXi75bh1bHVgPvEGJNcVJ70AtA4hB5Ij5EByhBxIjpADyRFyIDlCDiT3/+k+cA1Gc7yEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "img = mnist.train.images[0]\n",
    "print(img.shape)\n",
    "\n",
    "plt.imshow(img.reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 입력값 준비\n",
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
      "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 Convolution Layer 준비\n",
    "# 필터 : 크기는 3*3, 갯수는 32, 색상수는 1\n",
    "\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])  # 1차원 -> 4차원\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding=\"SAME\") #strides= 몇칸씩 이동할 것인지\n",
    "print(L1)\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 두 번째 Convolution Layer 준비\n",
    "# 필터 : 크기는 3*3, 갯수는 64, 색상수는 1\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "print(L2)\n",
    "L1 = tf.nn.relu(L2)\n",
    "print(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-9a53b19f5907>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-9a53b19f5907>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    b = tf.Variable(tf.random_normal([10]))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "##### Fully Connected Layer (Dense Layer) #####\n",
    "\n",
    "# hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 500\n",
    "\n",
    "# tensor graph 작성\n",
    "L2 = tf.reshape(L2, [-1, 7*7*64]) # 4차원 -> 2차원 \n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([7*7*64, 10])\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "# 비용 계산\n",
    "logit = tf.matmul(L2, W3) + b\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a4d3c11a670e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 정확도\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mis_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"정확도 : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logit' is not defined"
     ]
    }
   ],
   "source": [
    "# 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep FC\n",
    "\n",
    "+ 레이어 총 3개 사용, 입출력 갯수 128개 사용\n",
    "+ xavier 초기화\n",
    "+ dropout 사용\n",
    "+ training_epoch : 15\n",
    "+ batch_size : 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-13-812af3ecb029>:13: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch: 0001 cost= 0.497539008\n",
      "Epoch: 0002 cost= 0.154177050\n",
      "Epoch: 0003 cost= 0.107685490\n",
      "Epoch: 0004 cost= 0.088032060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-812af3ecb029>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mavg_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### hyper parameter 준비\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "prob = tf.placeholder(tf.float32)\n",
    "\n",
    "### 첫번째 레이어\n",
    "L3 = tf.reshape(L2, [-1, 7*7*64])\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([128]))\n",
    "logit3 = tf.matmul(L3, W3) + b3\n",
    "L3 = tf.nn.relu(logit3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=prob)\n",
    "\n",
    "### 두번째 레이어\n",
    "W4 = tf.get_variable(\"W4\", shape=[128, 128], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([128]))\n",
    "logit4 = tf.matmul(L3, W4) + b4\n",
    "L4 = tf.nn.relu(logit4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=prob)\n",
    "\n",
    "### 세번째 레이어\n",
    "W5 = tf.get_variable(\"W5\", shape=[128, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logit5 = tf.matmul(L4, W5) + b5\n",
    "L5 = tf.nn.softmax(logit5)\n",
    "L5 = tf.nn.dropout(L5, keep_prob=prob)\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit5, labels=y))\n",
    "\n",
    "# 최저 비용 구하기\n",
    "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "### tensor graph 실행\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([train, cost], feed_dict={X:batch_xs, y:batch_ys, prob:0.7})\n",
    "        avg_cost += c/total_batch\n",
    "        \n",
    "    print(\"Epoch:\", \"%04d\"%(epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "   \n",
    "\n",
    " ### 정확도\n",
    "is_correct = tf.equal(tf.argmax(logit5, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "print(\"정확도 : \", sess.run(accuracy, feed_dict={X:mnist.test.images, y:mnist.test.labels, prob:1}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 표지판 인식\n",
    "\n",
    "+ https://benchmark.ini.rub.de/gtsrb_dataset.html\n",
    "    + GTSRB_Final_Test_Images.zip\n",
    "    + GTSRB_Final_Training_Images.zip\n",
    "    \n",
    " \n",
    "+ 이미지(32 * 32) > Conv Layer1(Pooling) > Conv Layer2(Pooling) > FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from skimage.color import rgb2lab\n",
    "from skimage.transform import resize\n",
    "from collections import namedtuple\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상수 정의\n",
    "N_CLASSES = 43\n",
    "RESIZED_IMAGE = (32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'count',\n",
       " 'index',\n",
       " 'y']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset = namedtuple(\"Dataset\", [\"X\", \"y\"])\n",
    "dir(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_format(imgs):\n",
    "    return np.stack([img[:, :, np.newaxis] for img in imgs], axis=0).astype(np.float32)\n",
    "\n",
    "# 이미지 크기를 재조정하고 색상은 회색조로 변경, one-hot encoding\n",
    "def read_dataset_ppm(rootpath, n_labels, resize_to):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for c in range(n_labels):\n",
    "        full_path = rootpath + \"/\" + format(c, '05d') + \"/\"\n",
    "        \n",
    "        for img_name in glob.glob(full_path + \"*.ppm\"):  \n",
    "            img = plt.imread(img_name).astype(np.float32)\n",
    "            img = rgb2lab(img/255.0)[:, :, 0]  # 색상 변경\n",
    "            \n",
    "            img = resize(img, resize_to, mode=\"reflect\")\n",
    "            \n",
    "            label = np.zeros((n_labels,), dtype=np.float32 )\n",
    "            label[c] = 1.0\n",
    "            \n",
    "            images.append(img.astype(np.float32))\n",
    "            labels.append(label)\n",
    "\n",
    "    return Dataset(X=to_tf_format(images), y=np.array(labels))\n",
    "#------------------------------------\n",
    "ds = read_dataset_ppm(\"data/GTSRB/Final_Training/Images\", N_CLASSES, RESIZED_IMAGE)\n",
    "\n",
    "print(ds.X.shape)\n",
    "print(ds.y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 확인\n",
    "plt.imshow(ds.X[0,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[0, :])\n",
    "\n",
    "plt.imshow(ds.X[-1,:,:,:].reshape(RESIZED_IMAGE))\n",
    "print(ds.y[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(range(ds.X.shape[0]), ds.y, test_size=0.25, random_state=101)\n",
    "\n",
    "#np.array(X_train).shape\n",
    "\n",
    "idx_train, idx_test = train_test_split(range(ds.X.shape[0]), test_size=0.25, random_state=101)\n",
    "\n",
    "X_train = ds.X[idx_train, :, :, :]\n",
    "X_test = ds.X[idx_test, :, :, :]\n",
    "y_train = ds.y[idx_train, :]\n",
    "y_test = ds.y[idx_test, :]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 훈련(학습)과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 미니배치 준비\n",
    "def minibatcher(X, y, batch_size, shuffle):\n",
    "    assert X.shape[0] == y.shape[0]  # try exception 이나 if문으로 예외처리 가능, assert는 테스트만)\n",
    "    n_samples = X.shape[0]  # 전체 데이터 갯수\n",
    "    \n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(n_samples)\n",
    "    else:\n",
    "        idx = list(range(n_samples))\n",
    "    \n",
    "    for i in range(int(np.ceil(n_samples / batch_size))):\n",
    "        from_idx = i * batch_size\n",
    "        to_idx = (i+1) * batch_size\n",
    "        yield X[idx[from_idx : to_idx], :, :, :], y[idx[from_idx : to_idx], :]  # yield == next_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(10000, 32, 32, 1) (10000, 43)\n",
      "(9406, 32, 32, 1) (9406, 43)\n"
     ]
    }
   ],
   "source": [
    "### 미니배치 함수 테스트\n",
    "for i in minibatcher(X_train, y_train, 10000, True):\n",
    "    print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_no_activation_layer(in_tensors, n_units):\n",
    "    W = tf.get_variable(\"fc_W\", shape=[in_tensors.get_shape()[1], n_units], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"fc_b\", shape=[n_units], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "    return tf.matmul(in_tensors, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer():\n",
    "    return tf.nn.leaky_relu(fc_no_activation_layer(in_tensors, n_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(in_tensors, kernel_size, n_units):\n",
    "    W = tf.get_variable(\"conv_W\", [kernel_size, kernel_size, in_tensors.get_shape()[3], n_units], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(\"conv_b\", shape=[n_units], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    return tf.nn.leaky_relu(tf.nn.conv2d(in_tensors, W, strides=[1, 1, 1, 1], padding=\"SAME\") + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool_layer(in_tensors, sampling):\n",
    "    return tf.nn.max_pool(in_tensors, ksize=[1, sampling, sampling, 1], strides=[1, sampling, sampling, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(in_tensors, keep_proba, is_training):\n",
    "    return tf.cond(is_training, lambda:tf.nn.dropout(in_tensors, keep_proba), lambda:in_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Specification\n",
    "\n",
    "+ 2차원 convolution 5 * 5, 32 필터\n",
    "+ 2차원 convolution 5 * 5, 64 필터\n",
    "+ 평면화 계층(Flat Layer)\n",
    "+ Full Connected Layer, 1024개의 unit\n",
    "+ Dropout 40%\n",
    "+ Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(in_tensors, is_training):\n",
    "    \n",
    "    # First Layer : 5*5 2d convolution layer, 32 filters, 2X maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L1\"):\n",
    "        l1 = conv_layer(in_tensors, 5, 32)\n",
    "        l1 = maxpool_layer(l1, 2)\n",
    "        # l1 = maxpool_layer(conv_layer(in_tensors, 5, 32), 2)\n",
    "        l1_out = dropout(l1, 0.8, is_training)\n",
    "        \n",
    "    # Second Layer : 5*5 2d convolution layer, 64 filters, 2X maxpool, 20% dropout\n",
    "    with tf.variable_scope(\"L2\"):\n",
    "        l2 = maxpool_layer(conv_layer(in_tensors, 5, 64), 2)\n",
    "        l2_out = dropout(l2, 0.8, is_training)\n",
    "        \n",
    "    # Flat Layer\n",
    "    with tf.variable_scope(\"flatten\"):\n",
    "        l2_out_flat = tf.layers.flatten(l2_out)\n",
    "        \n",
    "    # Fully Connected Layer, 1024 neurons, 40% dropout\n",
    "    with tf.variable_scope(\"L3\"):\n",
    "        l3 = fc_layer(l2_out_flat, 1024)\n",
    "        l3_out = dropout(l3, 0.6, is_training)\n",
    "        \n",
    "    # output\n",
    "    with tf.variable_op_scope(\"out\"):\n",
    "        out_tensors = fc_no_activation_layer(l3_out, N_CLASSES)\n",
    "        \n",
    "    return out_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, learning_rate, max_epochs, batch_size):\n",
    "    in_X_tensors_batch = tf.placeholder(tf.float32, shape=(None, RESIZED_IMAGE[0], RESIZED_IMAGE[1], 1))  #shape=(29406, 32, 32, 1)\n",
    "    in_y_tensors_batch = tf.placeholder(tf.float32, shape=(None, N_CLASSES))\n",
    "    is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    logit = model(in_X_tensors_batch, is_training)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=in_y_tensors_batch))\n",
    "    train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch in range(max_epochs):\n",
    "            print(\"Epoch=\", epoch)\n",
    "            tf_score = []\n",
    "            \n",
    "            for mb in minibatcher(X_train, y_train, batch_size, shuffle=True):\n",
    "                _, c = sess.run([train, cost], feed_dict={in_X_tensors_batch:mb[0], in_y_tensors_batch:mb[1], is_training:True})\n",
    "                tf.score.append(c)\n",
    "                \n",
    "            print(\" train loss score=\", np.mean(tf_score))\n",
    "            \n",
    "        # 훈련이 끝난 후 테스트\n",
    "        print(\"TEST SET PERFORMANCE\")\n",
    "            \n",
    "        out_y_pred = tf.nn.softmax(logit)  #예측값\n",
    "        y_test_pred, test_cost = sess.run([out_y_pred, cost], feed_dict={in_X_tensors_batch:X_test, in_y_tensors_batch:y_test, is_training:False})\n",
    "         \n",
    "        print(\" test_loss_score=\", test_cost)\n",
    "        y_test_pred_classified = np.argmax(y_test_pred, axis=1).astype(np.int32)\n",
    "        y_test_true_classified = np.argmax(y_test, axis=1).astype(np.int32)\n",
    "        print(classification_report(y_test_true_classified, y_test_pred_classified))\n",
    "    \n",
    "        cm = confusion_matrix(y_test_true_classified, y_test_pred_classified)\n",
    "    \n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "        # And the log2 version, to enphasize the misclassifications\n",
    "        plt.imshow(np.log2(cm + 1), interpolation='nearest', cmap=plt.get_cmap(\"tab20\"))\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-f5ffae7ae6e6>:17: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\cecil\\anaconda3\\envs\\tf1\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fc_layer() takes 0 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-331d485a3f76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-930696a372f0>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, y_train, learning_rate, max_epochs, batch_size)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mis_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mlogit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_X_tensors_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_y_tensors_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-f5ffae7ae6e6>\u001b[0m in \u001b[0;36mmodel\u001b[1;34m(in_tensors, is_training)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Fully Connected Layer, 1024 neurons, 40% dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"L3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0ml3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfc_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml2_out_flat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0ml3_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fc_layer() takes 0 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "train_model(X_train, y_train, 0.001, 10, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. 일부 CNN계층과 FC계층을 추가/삭제를 통해서 성능이 어떻게 변하는지 확인\n",
    "2. dropout의 비율을 변경해보면서 결과가 과소적합 또는 과대적합되는지 확인\n",
    "3. 전체 epoch수와 batch size도 변경해서 결과 확인\n",
    "4. 실제 테스트 이미지를 통해서 사용할 수 있는 프로그램 작성\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
